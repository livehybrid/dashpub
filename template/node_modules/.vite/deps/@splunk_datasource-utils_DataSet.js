import __buffer_polyfill from 'vite-plugin-node-polyfills/shims/buffer'
globalThis.Buffer = globalThis.Buffer || __buffer_polyfill
import __global_polyfill from 'vite-plugin-node-polyfills/shims/global'
globalThis.global = globalThis.global || __global_polyfill
import __process_polyfill from 'vite-plugin-node-polyfills/shims/process'
globalThis.process = globalThis.process || __process_polyfill

import {
  require_lodash
} from "./chunk-FUC7W543.js";
import {
  __commonJS,
  __toESM,
  require_dist,
  require_dist2,
  require_dist3
} from "./chunk-2RF6DQJU.js";

// node_modules/@splunk/datasource-utils/DataSet.js
var require_DataSet = __commonJS({
  "node_modules/@splunk/datasource-utils/DataSet.js"(exports, module) {
    var import_dist = __toESM(require_dist());
    var import_dist2 = __toESM(require_dist2());
    var import_dist3 = __toESM(require_dist3());
    var __create = Object.create;
    var __defProp = Object.defineProperty;
    var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
    var __getOwnPropNames = Object.getOwnPropertyNames;
    var __getProtoOf = Object.getPrototypeOf;
    var __hasOwnProp = Object.prototype.hasOwnProperty;
    var __export = (target, all) => {
      for (var name in all)
        __defProp(target, name, { get: all[name], enumerable: true });
    };
    var __copyProps = (to, from, except, desc) => {
      if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames(from))
          if (!__hasOwnProp.call(to, key) && key !== except)
            __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
      }
      return to;
    };
    var __reExport = (target, mod, secondTarget) => (__copyProps(target, mod, "default"), secondTarget && __copyProps(secondTarget, mod, "default"));
    var __toESM2 = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
      // If the importer is in node compatibility mode or this is not an ESM
      // file that has been converted to a CommonJS file using a Babel-
      // compatible transform (i.e. "__esModule" has not been set), then set
      // "default" to the CommonJS "module.exports" for node compatibility.
      isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
      mod
    ));
    var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
    var DataSet_exports = {};
    __export(DataSet_exports, {
      default: () => DataSet
    });
    module.exports = __toCommonJS(DataSet_exports);
    var lodash_exports = {};
    __export(lodash_exports, {
      default: () => lodash_default
    });
    var defaultImport = __toESM2(require_lodash());
    __reExport(lodash_exports, require_lodash());
    var lodash_default = "default" in defaultImport ? defaultImport.default : defaultImport;
    var DataSet = class _DataSet {
      /**
       * @constructor
       * @param {Field[]} [fields= []] List of field name or field objects
       * @param {ColumnValue[][]} [columns=[]] List of column values related to fields
       * @returns DataSet
       */
      constructor(fields = [], columns = []) {
        this.fields = fields.map((field) => {
          if ((0, lodash_exports.isString)(field)) {
            return {
              name: field
            };
          }
          return field;
        });
        this.columns = columns;
      }
      /**
       * Returns a empty Dataset
       *
       * Examples:
       * ```js
       * const empty = DataSet.empty();
       * ```
       * @returns {DataSet} DataSet
       * @public
       */
      static empty() {
        return new _DataSet();
      }
      /**
       * Construct a Dataset with data in json array format
       *
       * Examples:
       * ```js
       *  const dataset = DataSet.fromJSONArray(
       *     [{ name: 'x' }, { name: 'y' }, { name: 'z' }],
       *     [{ x: 'a', y: 4, z: 70 }, { x: 'b', y: 5, z: 80 }, { x: 'c', y: 6, z: 90 }]
       *  );
       * ```
       * @param {FieldObj[]} [fields=[]] List of objects containing field names
       * @param {RowItem[]} [results=[]] List of objects containing results for each field
       * @returns {DataSet}
       * @public
       */
      static fromJSONArray(fields = [], results = []) {
        let fieldList = fields;
        if (fieldList == null || fieldList.length === 0) {
          if (results.length > 0) {
            const rowSample = results[0];
            fieldList = Object.keys(rowSample).map((field) => ({
              name: field
            }));
          } else {
            fieldList = [];
          }
        }
        const columns = fieldList.map(
          ({ name }) => results.reduce((col, row) => {
            col.push(row[name] === void 0 ? null : row[name]);
            return col;
          }, [])
        );
        return new _DataSet(fieldList, columns);
      }
      /**
       * Construct a Dataset with data in json columns format
       *
       * Examples:
       * ```js
       *  const dataset = DataSet.fromJSONCols(
       *     [{ name: 'x' }, { name: 'y' }, { name: 'z' }],
       *     [['a', 'b', 'c'], [4, 5, 6], [70, 80, 90]];
       *  );
       * ```
       * @param {Field[]} [fields=[]] List of fields
       * @param {ColumnValue[][]} [columns=[]] list of column values
       * @returns {DataSet}
       * @public
       */
      static fromJSONCols(fields = [], columns = []) {
        return new _DataSet(fields, columns);
      }
      /**
       * Construct a Dataset with data in json rows format
       *
       * Examples:
       * ```js
       *  const dataset = DataSet.fromJSONRows(
       *     [{ name: 'x' }, { name: 'y' }, { name: 'z' }],
       *     [['a', 4, 70], ['b', 5, 80], ['c', 6, 90]];
       *  );
       * ```
       * @param {Field[]} [fields=[]] List of fields
       * @param {ColumnValue[][]} [columns=[]] list of column values
       * @returns {DataSet}
       * @public
       */
      static fromJSONRows(fields = [], rows = []) {
        return new _DataSet(fields, (0, lodash_exports.zip)(...rows));
      }
      /**
       * Convert data to json array
       * @return {JSONArray} data in json array format
       * @public
       */
      toJSONArray() {
        return {
          fields: this.fields,
          results: (0, lodash_exports.zip)(...this.columns).map(
            (row) => (0, lodash_exports.zipObject)(
              this.fields.map((field) => field.name),
              row
            )
          )
        };
      }
      /**
       * Convert data to json columns
       * @return {JSONCols} data in json columns format
       * @public
       */
      toJSONCols() {
        const { fields, columns } = this;
        return { fields, columns };
      }
      /**
       * Convert data to json rows
       * @return {JSONRows} data in json rows format
       * @public
       */
      toJSONRows() {
        return {
          fields: this.fields,
          rows: (0, lodash_exports.zip)(...this.columns)
        };
      }
      /**
       * List all fields
       * @return {FieldObj[]} fields array
       * @public
       */
      getFields() {
        return this.fields;
      }
      /**
       * List data columns
       * @return {Object} columns array
       * @public
       */
      getColumns() {
        return this.columns;
      }
      /**
       *
       * @param {String} fieldName
       * @return {ColumnValue[]} column data
       * @public
       */
      getColumnByField(fieldName) {
        const index = (0, lodash_exports.findIndex)(this.fields, ({ name }) => name === fieldName);
        return this.columns[index];
      }
      /**
       *
       * @param {String} fieldName
       * @return {Boolean}
       * @public
       */
      hasField(fieldName) {
        return (0, lodash_exports.findIndex)(this.fields, ({ name }) => name === fieldName) !== -1;
      }
      /**
       * @return {Boolean} true if DataSet has no data
       * @public
       */
      isEmpty() {
        return this.columns.length === 0;
      }
      /**
       *
       * @param {DataSet} dataSet DataSet to compare
       * @return {Boolean} true if another dataset is equals to current one
       * @public
       */
      equals(dataSet) {
        return (0, lodash_exports.isEqual)(this.fields, dataSet.fields) && (0, lodash_exports.isEqual)(this.columns, dataSet.columns);
      }
      /**
       * Returns a slice of the dataset, useful for pagination.
       * @param options {Object}
       * @param options.count {Number} number of rows
       * @param options.offset {Number} starting row index
       * @returns {DataSet}
       * @public
       */
      getPage({
        count = 0,
        offset = 0
      }) {
        const end = count <= 0 ? void 0 : offset + count;
        return _DataSet.fromJSONCols(
          this.getFields(),
          this.getColumns().map((column) => column.slice(offset, end))
        );
      }
      /**
       * Get total number of rows. Note this is not affected by the pagination.
       * @public
       */
      getTotalCount() {
        var _a, _b;
        return (_b = (_a = this.columns[0]) == null ? void 0 : _a.length) != null ? _b : 0;
      }
    };
  }
});
export default require_DataSet();
//# sourceMappingURL=@splunk_datasource-utils_DataSet.js.map
